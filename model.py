import torch
from torch import nn

class DoubleConv(nn.Module):
  '''
  Main bulding block of the net. Consists of two consecutive convolutional
  2D layers with ReLU activation and dp% dropout.
  '''
  def __init__(self, in_channels, out_channels, dp):
    super().__init__()
    self.conv = nn.Sequential(
      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
      nn.ReLU(),
      nn.Dropout(p=dp),
      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),#, bias=False), -> if Normalisation exists
      nn.ReLU(),
      nn.Dropout(p=dp),
      nn.MaxPool2d(kernel_size = 2, stride = 2) #The pooling layer summarises the features
                                                #present in a region of the feature map generated by a
                                                #convolution layer. So, further operations are performed on
                                                #summarised features instead of precisely positioned features generated by the
                                                #convolution layer. This makes the model more robust to
                                                #variations in the position of the features in the input image.
    )

  def forward(self, x:torch.Tensor) -> torch.Tensor:
    return self.conv(x)

class PRGClassificator(nn.Module):
  def __init__(self, input_features: int, output_features: int, hidden_units: int, num_blocks: int, dp: float):
    super().__init__()
    self.forward_path_list = nn.ModuleList()

    for block in range(num_blocks):
      self.forward_path_list.append(DoubleConv(input_features, hidden_units, dp))
      input_features = hidden_units

    self.classifier = nn.Sequential(
      nn.Flatten(),
      nn.Linear(int(hidden_units*((80*(1/2**num_blocks))**2)), output_features),#As image size is decreased to NxN
                                                                        #due to num_blocks pooling layers,
                                                                        #where N = 80*(1/2)**(num_blocks)
    )

  def forward(self, x):
    for block in self.forward_path_list:
      x = block(x)
    return self.classifier(x)
